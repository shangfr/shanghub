{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 案例分析：客户精准营销(ML模型)\n",
    ">机器学习(Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。本案例采用领先的机器学习技术，研究UCI机器学习库中的「银行营销数据集(Bank Marketing Data Set)」，分析每一个客户的个性化需求，实现精准的产品营销与投放。\n",
    "\n",
    "\n",
    "一、背景与目标 \n",
    "\n",
    "1.1 背景\n",
    "\n",
    "根据客户历史营销响应数据，结合对市场未来需求数据、相关行业政策数据等，预测未来周期内客户营销响应，用以指导业务人员有针对性的营销，提高工作效率与经济效益。\n",
    "\n",
    "\n",
    "1.2 目标\n",
    "\n",
    "本实例使用的这些数据与葡萄牙银行机构的营销活动相关。这些营销活动以电话为基础，一般，银行的客服人员需要联系客户至少一次，以此确认客户是否将认购该银行的产品（定期存款）。因此，与该数据集对应的任务是「分类任务」，在本实例中，主要希望实现以下目标：\n",
    "\n",
    "- **通过二分类算法，预测客户是否购买该款产品。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NO | 字段名称 | 数据类型 | 字段描述 |\n",
    "| :-----| ----: | :----: | :----: |\n",
    "| 1 | ID | Int | 客户唯一标识 |\n",
    "| 2 | age | Int | 客户年龄 |\n",
    "| 3 | job | String | 客户的职业 |\n",
    "| 4 | marital | String | 婚姻状况 |\n",
    "| 5 | education | String | 受教育水平 |\n",
    "| 6 | default | String | 是否有违约记录 |\n",
    "| 7 | balance | Int | 每年账户的平均余额 |\n",
    "| 8 | housing | String | 是否有住房贷款 |\n",
    "| 9 | loan | String | 是否有个人贷款 |\n",
    "| 10 | contact | String | 与客户联系的沟通方式 |\n",
    "| 11 | day | Int | 最后一次联系的时间（几号） |\n",
    "| 12 | month | String | 最后一次联系的时间（月份） |\n",
    "| 13 | duration | Int | 最后一次联系的交流时长 |\n",
    "| 14 | campaign | Int | 在本次活动中，与该客户交流过的次数 |\n",
    "| 15 | pdays | Int | 距离上次活动最后一次联系该客户，过去了多久（999表示没有联系过） |\n",
    "| 16 | previous | Int | 在本次活动之前，与该客户交流过的次数 |\n",
    "| 17 | poutcome | String | 上一次活动的结果 |\n",
    "| 18 | y | Int | 预测客户是否会订购定期存款业务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\ShangFR\\\\Desktop\\\\eBrain\\\\Bank_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>291</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>may</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>5076</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>7</td>\n",
       "      <td>apr</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>104</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>14</td>\n",
       "      <td>jul</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-994</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>jul</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2974</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>may</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  age         job   marital  education default  balance housing loan  \\\n",
       "0   1   43  management   married   tertiary      no      291     yes   no   \n",
       "1   2   42  technician  divorced    primary      no     5076     yes   no   \n",
       "2   3   47      admin.   married  secondary      no      104     yes  yes   \n",
       "3   4   28  management    single  secondary      no     -994     yes  yes   \n",
       "4   5   42  technician  divorced  secondary      no     2974     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0   unknown    9   may       150         2     -1         0  unknown  0  \n",
       "1  cellular    7   apr        99         1    251         2    other  0  \n",
       "2  cellular   14   jul        77         2     -1         0  unknown  0  \n",
       "3  cellular   18   jul       174         2     -1         0  unknown  0  \n",
       "4   unknown   21   may       187         5     -1         0  unknown  0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bankdata\\\\train_set.csv', encoding='utf-8')  # 导入原始数据,指定UTF-8编码\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count          mean          std     min     25%      50%  \\\n",
      "ID        25317.0  12659.000000  7308.532719     1.0  6330.0  12659.0   \n",
      "age       25317.0     40.935379    10.634289    18.0    33.0     39.0   \n",
      "balance   25317.0   1357.555082  2999.822811 -8019.0    73.0    448.0   \n",
      "day       25317.0     15.835289     8.319480     1.0     8.0     16.0   \n",
      "duration  25317.0    257.732393   256.975151     0.0   103.0    181.0   \n",
      "campaign  25317.0      2.772050     3.136097     1.0     1.0      2.0   \n",
      "pdays     25317.0     40.248766   100.213541    -1.0    -1.0     -1.0   \n",
      "previous  25317.0      0.591737     2.568313     0.0     0.0      0.0   \n",
      "y         25317.0      0.116957     0.321375     0.0     0.0      0.0   \n",
      "\n",
      "              75%       max  null  \n",
      "ID        18988.0   25317.0   0.0  \n",
      "age          48.0      95.0   0.0  \n",
      "balance    1435.0  102127.0   0.0  \n",
      "day          21.0      31.0   0.0  \n",
      "duration    317.0    3881.0   0.0  \n",
      "campaign      3.0      55.0   0.0  \n",
      "pdays        -1.0     854.0   0.0  \n",
      "previous      0.0     275.0   0.0  \n",
      "y             0.0       1.0   0.0  \n"
     ]
    }
   ],
   "source": [
    "#查看数据概述\n",
    "explore = data.describe(include=None).T \n",
    "explore['null'] = len(data) - explore['count']  # 计算空值数\n",
    "print(explore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22356\n",
      "1     2961\n",
      "Name: y, dtype: int64\n",
      "job 缺失率:0.45%\n",
      "education 缺失率:2.94%\n",
      "contact 缺失率:20.13%\n",
      "poutcome 缺失率:57.17%\n"
     ]
    }
   ],
   "source": [
    "print(data.y.value_counts())\n",
    "data.shape\n",
    "data_s = data.select_dtypes(include=['object'])\n",
    "\n",
    "for i in range(len(data_s.columns)):\n",
    "    u = sum(data_s.iloc[:,i] == 'unknown')\n",
    "    if u > 0:\n",
    "        print(data_s.columns[i],'缺失率:%.2f%%'%(100*u/36169))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# data_df = data.drop(['ID','contact','poutcome'], axis=1)\n",
    "# data_df.drop_duplicates(subset=['A','B'],keep='first',inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age           int64\n",
      "job          object\n",
      "marital      object\n",
      "education    object\n",
      "default      object\n",
      "balance       int64\n",
      "housing      object\n",
      "loan         object\n",
      "contact      object\n",
      "day           int64\n",
      "month        object\n",
      "duration      int64\n",
      "campaign      int64\n",
      "pdays         int64\n",
      "previous      int64\n",
      "poutcome     object\n",
      "y             int64\n",
      "dtype: object\n",
      "object    9\n",
      "int64     8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ont-hot 编码\n",
    "data_df = data.drop(['ID'], axis=1)\n",
    "print(data_df.dtypes)\n",
    "print(data_df.dtypes.value_counts())\n",
    "data_dummy = pd.get_dummies(data_df.select_dtypes(include=['object']))\n",
    "data_oh = pd.concat([data_dummy, data_df.select_dtypes(exclude=['object'])], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_oh.drop(['y'], axis=1)   \n",
    "y = data_oh.y                  \n",
    "#测试集占训练集30%\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDT(Gradient Boosting Decision Tree)是目前工业和各种竞赛中非常抢手的模型，性能表现出色，特别是XgBoost，LightGBM推出后，模型性能和运行效率进一步提升。GBDT模型是一个集成模型，基分类器采用CART，集成方式为Gradient Boosting。\n",
    "\n",
    "CART是一个分类回归二叉决策树，构建一棵二叉树，主要涉及到一下一个问题：\n",
    "\n",
    "怎么分裂一个特征？\n",
    "怎么选择最佳分裂特征？\n",
    "确定分裂的停止条件？\n",
    "决策树的优化：剪枝方法？\n",
    "因为CART是一棵二叉树，所以在分裂特征时与 ID3、C4.5有区别。\n",
    "CART在分类时采用最小平方误差来选择最优切分特征和切分点。\n",
    "\n",
    "Boosting\n",
    "Boosting是一种模型的组合方式，我们熟悉的AdaBoost就是一种Boosting的组合方式。和随机森林并行训练不同的决策树最后组合所有树的bagging方式不同，Boosting是一种递进的组合方式，每一个新的分类器都在前一个分类器的预测结果上改进，所以说boosting是减少bias而bagging是减少variance的模型组合方式。\n",
    "下面是GDBT的一个简单例子：判断用户是否会喜欢电脑游戏，特征有年龄，性别和职业。需要注意的是，GBDT无论是用于分类和回归，采用的都是回归树，分类问题最终是将拟合值转换为概率来进行分类的。\n",
    "\n",
    "![graph.png](attachment:graph.png)\n",
    "在上图中,每个用户的最后的拟合值为两棵树的结果相加。\n",
    "\n",
    "GBDT的主要优点：\n",
    "\n",
    "　　1）可以灵活的处理各种类型的数据\n",
    "\n",
    "　　2）预测的准确率高\n",
    "\n",
    "　　3）使用了一些健壮的损失函数，如huber，可以很好的处理异常值\n",
    "\n",
    "GBDT的缺点：\n",
    "\n",
    "　　1）由于基学习器之间的依赖关系，难以并行化处理，不过可以通过子采样的SGBT来实现部分并行。\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9072\n",
      "AUC Score (Train): 0.922007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "GBDT= GradientBoostingClassifier(random_state=90)\n",
    "GBDT.fit(Xtrain, ytrain)\n",
    "GBDT.score(Xtest, ytest)\n",
    "y_pred= GBDT.predict(Xtest)\n",
    "y_predprob= GBDT.predict_proba(Xtest)[:,1]\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytest.values, y_pred))\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytest, y_predprob))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习中的一大难点就是参数调优，每个模型会有很多可调节的模型参数。\n",
    "模型参数（Hyperparameters）调优的通用做法是Grid Search或者Random Search，Sklearn中已经提供了相应的方法GridSearchCV和RandomizedSearchCV。 这两种搜索方法都包括Search和CV两步，即搜索和交叉验证。\n",
    "\n",
    "GridSearch在需要调节参数的指定取值范围，遍历所有组合寻，比如有两个参数，第一个有两种值，第二个有三种，那就会有六种组合。GridSearch会对每种参数组合做一遍交叉验证，记录模型得分，最后找到得分最好的那个参数组合。GridSearchCV可以保证在指定的参数范围内找到精度最高的参数，但它要求遍历所有可能参数的组合，在面对大数据集和多参数的情况下会非常耗时。\n",
    "\n",
    "RandomizedSearchCV的使用方法其实是和GridSearchCV一致的，但它以随机在参数空间中采样的方式代替了GridSearchCV对于参数的网格搜索，在对于有连续变量的参数时，RandomizedSearchCV会将其当作一个分布进行采样，它的搜索能力取决于设定的循环n_iter参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " param_grid:  {'max_depth': array([10, 15]), 'min_samples_split': array([50, 60, 70, 80, 90])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='auto',\n",
       "                                                  random_state=90,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': array([10, 15]),\n",
       "                         'min_samples_split': array([50, 60, 70, 80, 90])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "# 网格寻参,寻找最优'max_depth'、'min_samples_split'；耗时费力，数据集大的时候不好用\n",
    "\n",
    "param_grid = {'max_depth':np.arange(10, 20, 5), #决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split\n",
    "              'min_samples_split':np.arange(50, 100, 10)}\n",
    "print(\" param_grid: \", param_grid)\n",
    "\n",
    "gbdt = GradientBoostingClassifier(random_state=90)\n",
    "GS = GridSearchCV(gbdt,param_grid,n_jobs=-1,cv=3)\n",
    "GS.fit(Xtrain,ytrain)\n",
    "# print('网格搜索-度量记录：',GS.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',GS.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',GS.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',GS.best_estimator_)  # 获取最佳度量时的分类器模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网格搜索-最佳度量值: 0.9050279329608939\n",
      "网格搜索-最佳参数： {'subsample': 0.731578947368421, 'n_estimators': 148, 'min_samples_split': 700, 'min_samples_leaf': 60, 'max_features': 9, 'max_depth': 2, 'learning_rate': 0.1}\n",
      "网格搜索-最佳模型： GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
      "                           max_features=9, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=60, min_samples_split=700,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=148,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=0.731578947368421,\n",
      "                           tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 寻参\n",
    "param_dist = {\n",
    "    'learning_rate':np.linspace(0.1,2,20), #步长(learning rate)和迭代次数(n_estimators)\n",
    "    'n_estimators':range(80,200,4),\n",
    "    'max_depth':range(2,15,1), #决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split、叶子节点最少样本数\n",
    "    'min_samples_split':range(100,801,200),\n",
    "    'min_samples_leaf':range(60,101,10),\n",
    "    'max_features':range(7,20,2), #最大特征数max_features\n",
    "    'subsample':np.linspace(0.7,0.9,20) #子采样的比例\n",
    "}\n",
    "\n",
    "gbdt = GradientBoostingClassifier()\n",
    "RS = RandomizedSearchCV(gbdt,param_dist,cv = 3,scoring = 'accuracy',n_iter=10,n_jobs = -1)\n",
    "\n",
    "#在训练集上训练\n",
    "RS.fit(Xtrain, ytrain)\n",
    "#返回最优的训练器\n",
    "\n",
    "#print('网格搜索-度量记录：',RS.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',RS.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',RS.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',RS.best_estimator_)  # 获取最佳度量时的分类器模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9051\n",
      "AUC Score (Train): 0.916130\n"
     ]
    }
   ],
   "source": [
    "# 建模\n",
    "GBDT = RS.best_estimator_\n",
    "GBDT.fit(Xtrain, ytrain)\n",
    "GBDT.score(Xtest, ytest)\n",
    "y_pred= GBDT.predict(Xtest)\n",
    "y_predprob= GBDT.predict_proba(Xtest)[:,1]\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytest.values, y_pred))\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytest, y_predprob))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型保存与载入\n",
    "import joblib\n",
    "joblib.dump(GBDT, \"model\\\\GBDT.model\")\n",
    "GBDT = joblib.load(\"model\\\\GBDT.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入测试集，结果输出\n",
    "\n",
    "data_test = pd.read_csv('bankdata\\\\test_set.csv')\n",
    "ID = data_test.ID\n",
    "data_test.drop(['ID'], axis=1, inplace=True)\n",
    "data_test_dummy = pd.get_dummies(data_test.select_dtypes(include=['object']))\n",
    "data_test_oh = pd.concat([data_test_dummy, data_test.select_dtypes(exclude=['object'])], axis=1)\n",
    "\n",
    "pred = GBDT.predict_proba(data_test_oh)\n",
    "data_out = pd.DataFrame(pred, index=ID, columns=['pred0', 'pred'])\n",
    "data_out.drop('pred0', axis=1, inplace=True)\n",
    "data_out.to_csv('bankdata\\\\result1009.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
